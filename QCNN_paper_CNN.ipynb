{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcKI5rMVSYGR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from torchsummary import summary\n",
        "import plotly.subplots as sp\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"mnist\"\n",
        "Encoding = \"pca8\"\n",
        "input_size = 8\n",
        "pca_n_components = 8\n",
        "classes = 10\n",
        "final_layer_size = int(input_size / 4)\n",
        "print(f\"device being used --- {device}\")\n",
        "print(f'final layer size of the cnn model {final_layer_size}')\n",
        "plot_pca = True"
      ],
      "metadata": {
        "id": "sgwMdt4JSxrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasize to choose for training and test set\n",
        "train_datasize = 2000\n",
        "test_datasize = 1000\n",
        "\n",
        "if dataset_name == \"fashion_mnist\":\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "elif dataset_name == \"mnist\":\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "len_unique_classes = np.unique(y_test)\n",
        "print(f\"Loaded Fashion MNIST dataset with {len(x_train)} training samples and {len(x_test)} test samples with # classes {len_unique_classes}\")\n",
        "\n",
        "# shuffle the training data\n",
        "train_indices = np.random.permutation(len(x_train))\n",
        "x_train = x_train[train_indices]\n",
        "y_train = y_train[train_indices]\n",
        "\n",
        "# shuffle the test data\n",
        "test_indices = np.random.permutation(len(x_test))\n",
        "x_test = x_test[test_indices]\n",
        "y_test = y_test[test_indices]\n",
        "\n",
        "# slice the datasize\n",
        "x_train = x_train[:train_datasize]\n",
        "x_test = x_test[:test_datasize]\n",
        "y_train = y_train[:train_datasize]\n",
        "y_test = y_test[:test_datasize]\n",
        "\n",
        "# count the number of each class in x_train and y_test\n",
        "train_class_counts = Counter(y_train)\n",
        "test_class_counts = Counter(y_test)\n",
        "\n",
        "# the class counts in x_train\n",
        "print(\"Class counts in x_train:\")\n",
        "for label, count in train_class_counts.items():\n",
        "    print(f\"Class {label}: {count}\")\n",
        "\n",
        "# the class counts in x_test\n",
        "print(\"Class counts in x_test:\")\n",
        "for label, count in test_class_counts.items():\n",
        "    print(f\"Class {label}: {count}\")\n",
        "\n",
        "def check_imbalance(class_counts, datasize):\n",
        "  avg_count = datasize / 10\n",
        "  # taking imbalance threshold, 20% of average count\n",
        "  threshold = 0.2 * avg_count\n",
        "  for label, count in class_counts.items():\n",
        "    if abs(count - avg_count) > threshold:\n",
        "      return True, label, count\n",
        "  return False, None, None\n",
        "\n",
        "# check for imbalance in training data and test_data\n",
        "is_imbalanced_train, train_imbalanced_class, train_imbalanced_count = check_imbalance(train_class_counts, train_datasize)\n",
        "if is_imbalanced_train:\n",
        "    print(f\"\\nImbalance detected in training data for class {train_imbalanced_class} with count {train_imbalanced_count}\")\n",
        "else:\n",
        "    print(\"\\nNo significant imbalance detected in training data\")\n",
        "is_imbalanced_test, test_imbalanced_class, test_imbalanced_count = check_imbalance(test_class_counts, test_datasize)\n",
        "if is_imbalanced_test:\n",
        "    print(f\"\\nImbalance detected in test data for class {test_imbalanced_class} with count {test_imbalanced_count}\")\n",
        "else:\n",
        "    print(\"\\nNo significant imbalance detected in test data\")"
      ],
      "metadata": {
        "id": "ykceVAkqUlsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the first 5 images\n",
        "plt.figure(figsize=(10, 2))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Brh0n_SwWVc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the images data\n",
        "X_train, X_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0\n",
        "Y_train = y_train\n",
        "Y_test = y_test"
      ],
      "metadata": {
        "id": "nBMkYG3HaGxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply pca and flatten original 28x28 images\n",
        "X_train = tf.image.resize(X_train[:], (784, 1)).numpy()\n",
        "X_test = tf.image.resize(X_test[:], (784, 1)).numpy()\n",
        "X_train, X_test = tf.squeeze(X_train), tf.squeeze(X_test)\n",
        "# apply pca\n",
        "pca = PCA(pca_n_components)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "# Explained variance ratio\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(f\"Explained variance ratio of the {pca_n_components} components:\", explained_variance)\n",
        "if plot_pca:\n",
        "  # plot the first three PCA components\n",
        "  df = pd.DataFrame({\n",
        "        'Principal Component 1': X_train[:, 0],\n",
        "        'Principal Component 2': X_train[:, 1],\n",
        "        'Principal Component 3': X_train[:, 2],\n",
        "        'Digit': y_train\n",
        "    })\n",
        "  # create the interactive 3D plot\n",
        "  fig = px.scatter_3d(df, x='Principal Component 1', y='Principal Component 2', z='Principal Component 3',\n",
        "                      color='Digit', labels={'Digit': 'Digit'}, opacity=0.7)\n",
        "  fig.update_layout(title=f'PCA of {dataset_name} dataset (First 3 Components of {pca_n_components})',\n",
        "                    scene = dict(\n",
        "                          xaxis_title='Principal Component 1',\n",
        "                          yaxis_title='Principal Component 2',\n",
        "                          zaxis_title='Principal Component 3'), width=800, height=600)\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "61mnPJ9-bCzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_feature = 2\n",
        "# Define the CNN model\n",
        "CNN_model = nn.Sequential(\n",
        "    nn.Conv1d(in_channels=1, out_channels=n_feature, kernel_size=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool1d(kernel_size=2),\n",
        "    nn.Conv1d(in_channels=n_feature, out_channels=n_feature, kernel_size=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool1d(kernel_size=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(n_feature * final_layer_size, classes),  # Output size for MNIST 10 classes\n",
        ")\n",
        "if device == \"cuda\":\n",
        "  CNN_model.to(device)"
      ],
      "metadata": {
        "id": "38LsGHvgS1DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torchsummary to get the model summary\n",
        "sample_image = X_test[0].reshape(1, X_test[0].shape[0])\n",
        "summary(CNN_model, input_size=sample_image.shape)"
      ],
      "metadata": {
        "id": "8VApEgEle2UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute accuracy\n",
        "def compute_accuracy(preds, labels):\n",
        "  _, preds_max = torch.max(preds, 1)\n",
        "  correct = (preds_max == labels).sum().item()\n",
        "  return correct / labels.size(0)"
      ],
      "metadata": {
        "id": "w_cuzyqqpNwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 30\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "\n",
        "train_loss_history = []\n",
        "train_acc_history = []\n",
        "test_loss_history = []\n",
        "test_acc_history = []\n",
        "\n",
        "optimizer = torch.optim.SGD(CNN_model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "cost_function = nn.CrossEntropyLoss()\n",
        "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)\n",
        "\n",
        "tr_steps_per_epoch = len(X_train) // batch_size\n",
        "\n",
        "print(f'starting training model for {n_epochs} epochs')\n",
        "for epoch in range(n_epochs):\n",
        "  epoch_loss = 0\n",
        "  epoch_accuracy = 0\n",
        "  steps = 0\n",
        "  # shuffle the data for each epoch\n",
        "  indices = np.random.permutation(len(X_train))\n",
        "  X_train_shuffled = X_train[indices]\n",
        "  Y_train_shuffled = Y_train[indices]\n",
        "  for step in range(tr_steps_per_epoch):\n",
        "    # create mini-batch\n",
        "    X_batch = X_train_shuffled[step * batch_size: (step + 1) * batch_size]\n",
        "    Y_batch = Y_train_shuffled[step * batch_size: (step + 1) * batch_size]\n",
        "    X_train_batch_torch = torch.tensor(X_batch, dtype=torch.float32).view(batch_size, 1, input_size).to(device)\n",
        "    #X_train_batch_torch.resize_(batch_size, 1, input_size)\n",
        "    Y_train_batch_torch = torch.tensor(Y_batch, dtype=torch.long).to(device)\n",
        "    # zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "    # send the data to model\n",
        "    Y_pred_batch_torch = CNN_model(X_train_batch_torch)\n",
        "    # compute loss function\n",
        "    loss = cost_function(Y_pred_batch_torch, Y_train_batch_torch)\n",
        "    train_loss_history.append(loss.item())\n",
        "\n",
        "    # backward pass and optimize\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Accumulate loss and accuracy\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_accuracy += compute_accuracy(Y_pred_batch_torch, Y_train_batch_torch)\n",
        "    steps += 1\n",
        "  # compute average loss and accuracy for the epoch\n",
        "  avg_epoch_loss = epoch_loss / steps\n",
        "  avg_epoch_accuracy = epoch_accuracy / steps\n",
        "  train_loss_history.append(avg_epoch_loss)\n",
        "  train_acc_history.append(avg_epoch_accuracy)\n",
        "\n",
        "  print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {avg_epoch_loss:.4f}, Accuracy: {avg_epoch_accuracy:.4f}')\n",
        "  # setup the scheduler\n",
        "  #scheduler.step(avg_epoch_accuracy)"
      ],
      "metadata": {
        "id": "gM-PdQYyfGQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training history using Plotly\n",
        "fig = sp.make_subplots(rows=1, cols=2, subplot_titles=(\"Training Loss\", \"Training Accuracy\"))\n",
        "\n",
        "# Training Loss\n",
        "fig.add_trace(go.Scatter(x=list(range(1, n_epochs+1)), y=train_loss_history, mode='lines+markers', name='Loss'), row=1, col=1)\n",
        "\n",
        "# Training Accuracy\n",
        "fig.add_trace(go.Scatter(x=list(range(1, n_epochs+1)), y=train_acc_history, mode='lines+markers', name='Accuracy'), row=1, col=2)\n",
        "\n",
        "fig.update_layout(title_text=f\"Training Loss and Accuracy Over Epochs : {dataset_name}\", height=600, width=1000,)\n",
        "fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Loss\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Accuracy\", row=1, col=2)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8chfJl344X-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "def evaluate_model(model, X_test, Y_test, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    X_test_torch = torch.tensor(X_test, dtype=torch.float32).view(len(X_test), 1, input_size).to(device)\n",
        "    Y_test_torch = torch.tensor(Y_test, dtype=torch.long).to(device)\n",
        "    with torch.no_grad():\n",
        "      Y_pred_test_torch = model(X_test_torch)\n",
        "    test_accuracy = compute_accuracy(Y_pred_test_torch, Y_test_torch)\n",
        "    return Y_pred_test_torch.cpu().numpy(), test_accuracy\n",
        "\n",
        "predictions, test_accuracy = evaluate_model(CNN_model, X_test, Y_test, device)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "x3pTCJFzAThg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix and Classification Report\n",
        "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
        "class_report = classification_report(Y_test, predicted_labels, output_dict=True)\n",
        "\n",
        "# Plotting the confusion matrix using seaborn\n",
        "plt.figure()\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(classes), yticklabels=range(classes))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title(f'CNN Confusion Matrix : {dataset_name}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wjFEjO_qBlby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert classification report to DataFrame\n",
        "class_report_df = pd.DataFrame(class_report).transpose()\n",
        "\n",
        "# Plotting the classification report using Seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(class_report_df.iloc[:-1, :-1].T, annot=True, cmap='Blues')\n",
        "plt.title(f'CNN Classification Report : {dataset_name}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yd3ki6_mFqst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}